### item48 스트림 병렬화는 주의해서 적용하라

- 자바는 주류 언어 중, 동시성 프로그래밍 측면에서 항상 앞서 있었다. 자바 8부터 parallel 메서드만 한 번 호출하면 파이프라인을 작성하기가 점점 쉬워지고 있지만, 이를 빠르게 작성하는 일은 별개의 이야기이다.
- 동시성 프로그래밍을 할 때는 안전성과 응답 가능 상태를 유지하기 위해 애써야 하는데, 병렬 스트림 파이프라인 프로그래밍에서도 다를 바 없다.
- 아이템 45에 다루었던 메르센 소수를 다시 살펴보자.

```java
public static void main(String[] args) {
  prims().map(p -> TWO.pow(p.intValueExact()).subtract(ONE))
  .filter(mersenne -> mersenne.isProbablePrime(50))
  .limit(20)
  .forEach(System.out.println);
}

static Stream<BigInteger> primes() {
  return Stream.iterate(TWO, BigInteger::nextProbablePrime);
}
```

- 이 프로그램의 속도를 높이고 싶어 스트림 파이프라인의 parallel()을 호출했다고 치자. 이렇게 하면 안타깝게도 아무것도 출력하지 못하면서 CPU는 90%나 잡아먹는 상태가 무한히 계속된다(응답 불가). 결국에는 완료될지 몰라도 1시간 반이 지나 강제 종료할 때까지 아무 결과 출력하지 않는다.

  왜 그럴까? 그 이유는, 스트림 라이브러리가 이 파이프라인을 병렬화하는 방법을 찾아내지 못했기 때문이다.

  - 환경이 아무리 좋더라도 데이터 소스가 Stream.iterate거나 중간 연산으로 limit를 쓰면 파이프라인 병렬화로는 성능 개선을 기대할 수 없다. 그런데 위의 코드는 두 문제를 모두 지니고 있다.

    뿐만 아니라, 파이프라인 병렬화는 limit를 다룰 때 CPU 코어가 남는다면 원소를 몇 개 더 처리한 후 제한된 개수 이후의 결과를 버려도 아무런 해가 없다고 가정한다. 그런데 이 코드의 경우 새롭게 메르센 소수를 찾을 때마다 그 전 소수를 찾을 때보다 두 배 정도 더 오래 걸린다. 즉, 원소 하나를 계산하는 비용이 그 이전까지의 원소 전부를 계산한 비용을 합친 것만큼 든다는 뜻이다.

- 스트림의 소스가 ArrayList, HashMap 등의 인스턴스거나 배열, int 범위, long 범위일 때 병렬화의 효과가 가장 좋다. 이 자료들은 모두 데이터를 원하는 크기로 정확하게 나눌 수 있고 다수의 스레드에 분배하기 좋다는 특성이 있다. 또 원소들을 순차적으로 실행할 때 참조 지역성이 뛰어나다.

- 참조 지역성이란 이웃한 원소의 참조들이 메모리에 연속해서 저장되어 있다는 뜻이다. (마치 배열처럼)

- 하지만 참조들이 가리키는 실제 객체가 메모리에서 서로 떨어져 있을 수 있는데, 이러면 참조 지역성이 떨어진다. 참조 지역성이 낮으면 스레드는 데이터가 주 메모리에서 캐시 메모리로 전송되어 오기만을 기다린다. 따라서, 참조 지역성은 다량의 데이터를 처리하는 벌크 연산을 병렬화할 때 아주 중요한 요소이다. (참고로 참조 지역성이 가장 뛰어난 자료구조는 배열이다.)

- 스트림 파이프라인의 종단 연산의 동작 방식도 병렬 수행 효율에 큰 영향을 준다. 종단 연산이 파이프라인 전체 작업에서 상당 비중을 차지하기 때문이다.

  종단 연산 중 병렬화에 가장 적합한 것은 축소이다. 축소는 파이프라인에서 만들어진 모든 원소를 하나로 합치는 작업으로, Stream의 reduce, min, max, count, sum 같은 메서드들이 수행한다. 반면, 가변 축소를 수행하는 Stream의 collect 메서드는 컬렉션들을 합치는 부담이 크기 때문에 병렬화에 적합하지 않다.

- 지금까지 내용에서의 교훈! _스트림을 마구 잡이로 병렬화하거나 잘못 병렬화하면 성능이 나빠질 뿐만 아니라 결과 자체가 잘못되거나 예상 못한 동작이 발생할 수 있다!_
- 결과가 잘못되거나 오작동하는 것을 안전 실패라고 한다. 안전 실패는 병렬화한 파이프라인이 사용하는 메서드나 객체가 명세대로 동작하지 않을 때 벌어진다.
  Stream 명세는 이때 사용하는 객체에 관해 규약을 정해놨다.

  -예를 들어, Stream의 reduce 연산에 건네지는 accumulator(누적기)와 combiner(결합기) 함수는 반드시 결합법칙을 만족하고, 간섭받지 않고, 상태를 갖지 않아야 한다.

  이 요구사항을 지키지 못하는 상태라도 파이프라인을 *순차적*으로만 수행하면 문제없다.

- 스트림 병렬화는 데이터 소스 스트림이 효율적으로 나눠지고, 병렬화하거나 빨리 끝나는 종단 연산을 사용하고, 함수 객체들도 간섭하지 않더라도, 파이프라인이 수행하는 진짜 작업이 병렬화에 드는 추가 비용을 상쇄하지 못한다면 성능 향상은 미미할 수 있다.

  그래서 이를 실제로 성능 향상이 될지 추정해보는 간단한 방법이 있다. (스트림 안의 원소 수) \* (원소당 수행되는 코드줄 수) 공식을 이용하는 것이다. 이 값이 최소 수십만은 되어야 성능 향상을 맛볼 수 있다.

- 스트림 병렬화는 오직 성능 최적화 수단임을 기억해야 한다. 반드시 테스르를 거쳐서 병렬화를 사용할 가치가 있는지 확인해야 한다. 그렇지 않으면 이를 사용해도 손해만 보는 상황이 생긴다.

-마지막으로 병렬화가 효과를 제대로 발휘한 간단한 예를 보자.

```java
static long pi(long n) {
  return LongStream.rangeClosed(2, n)
  .mapToObj(BigInteger::valueOf)
  .filter(i -> i.isProbablePrime(50))
  .count();
}
```

n보다 작거나 같은 소수의 개수를 계산하는 함수이다. 이를 돌려보면 31초가 걸렸는데 여기에 parallel() 호출을 하나 추가하면 9.2초로 단축됐다.

```java
static long pi(long n) {
  return LongStream.rangeClosed(2, n)
  .parallel()
  .mapToObj(BigInteger::valueOf)
  .filter(i -> i.isProbablePrime(50))
  .count();
}
```

물론 이 역시도 항상 옳은 것은 아니다. n이 엄청 거대해지면 레머의 공식이라는 훨씬 효율적인 알고리즘을 사용하는 것이 옳다.

- 무작위 수들로 이뤄진 스트림을 병렬화할 때는 ThreadLocalRandom(구식으로는 그냥 Random)보다는 SplittableRandom 인스턴스를 이용하자. SplittableRandom은 정확히 이럴 때 사용하라고 설계된 것이라 성능이 선형으로 증가한다. 한편 ThreadLocalRandom은 단일 스레드에서 쓰고자 만들어졌다. 병렬 스트림용 데이터 소스에도 쓸 수 있지만 SplittableRandom만큼 빠르지는 않다. 마지막으로 그냥 Random은 모든 연산을 동기화하기 때문에 병렬 처리하면 최악의 성능을 보일 것이다.
